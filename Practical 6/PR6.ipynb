{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self,input,hidden,output):\n",
    "        self.ip_size=input\n",
    "        self.hidden_size=hidden\n",
    "        self.op_size=output\n",
    "\n",
    "        self.hidden_weights=np.random.randn(self.ip_size,self.hidden_size)\n",
    "        self.output_weights=np.random.randn(self.hidden_size,self.op_size)\n",
    "        self.hidden_bais=np.random.randn(1,self.hidden_size)\n",
    "        self.output_bais=np.random.randn(1,self.op_size)\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1-x)\n",
    "\n",
    "    def forward_propagation(self,x):\n",
    "        self.hidden_input=np.dot(x,self.hidden_weights) + self.hidden_bais\n",
    "        self.hidden_output=self.sigmoid(self.hidden_input)\n",
    "\n",
    "        self.output_input=np.dot(self.hidden_output,self.output_weights) + self.output_bais\n",
    "        self.output=self.sigmoid(self.output_input)\n",
    "        return self.output\n",
    "    \n",
    "    def backward_propagation(self,X,Y,output):\n",
    "        error=Y-output\n",
    "        delta_op_layer=error * self.sigmoid_derivative(output)\n",
    "\n",
    "        hidden_error=delta_op_layer.dot(self.output_weights.T)\n",
    "        delta_hidden=hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        self.output_weights+=self.hidden_output.T.dot(delta_op_layer)\n",
    "        self.output_bais+=np.sum(delta_op_layer,axis=0,keepdims=True)\n",
    "        self.hidden_weights+=X.T.dot(delta_hidden)\n",
    "        self.hidden_bais+=np.sum(delta_hidden,axis=0,keepdims=True)\n",
    "    \n",
    "    def train(self,X,Y,epochs=100):\n",
    "        for epoc in range(epochs):\n",
    "            output=self.forward_propagation(X)\n",
    "            self.backward_propagation(X,Y,output)\n",
    "            if epoc % 100 == 0:\n",
    "                loss = np.mean(np.square(y - output))\n",
    "                print(f'Epoch {epoc}, Loss: {loss:.4f}')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([[0],[1],[1],[0]])\n",
    "ip_size=2\n",
    "hidden_size=4\n",
    "op_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.4245\n",
      "Epoch 100, Loss: 0.2017\n",
      "Epoch 200, Loss: 0.1265\n",
      "Epoch 300, Loss: 0.0333\n",
      "Epoch 400, Loss: 0.0129\n",
      "Epoch 500, Loss: 0.0073\n",
      "Epoch 600, Loss: 0.0050\n",
      "Epoch 700, Loss: 0.0037\n",
      "Epoch 800, Loss: 0.0029\n",
      "Epoch 900, Loss: 0.0024\n",
      "Prediction after Training:\n",
      "[[0.0454811 ]\n",
      " [0.95438458]\n",
      " [0.95872329]\n",
      " [0.04689315]]\n"
     ]
    }
   ],
   "source": [
    "nn=NN(ip_size,hidden_size,op_size)\n",
    "nn.train(X, y, epochs=1000)\n",
    "print(\"Prediction after Training:\")\n",
    "print(nn.forward_propagation(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# class NN:\n",
    "#     def __init__(self, input, hidden, output):\n",
    "#         # Initialize the number of nodes in the input, hidden, and output layers\n",
    "#         self.ip_size = input\n",
    "#         self.hidden_size = hidden\n",
    "#         self.op_size = output\n",
    "\n",
    "#         # Randomly initialize weights and biases for hidden and output layers\n",
    "#         self.hidden_weights = np.random.randn(self.ip_size, self.hidden_size)\n",
    "#         self.output_weights = np.random.randn(self.hidden_size, self.op_size)\n",
    "#         self.hidden_bais = np.random.randn(1, self.hidden_size)\n",
    "#         self.output_bais = np.random.randn(1, self.op_size)\n",
    "\n",
    "#     def sigmoid(self, x):\n",
    "#         # Sigmoid activation function\n",
    "#         return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "#     def sigmoid_derivative(self, x):\n",
    "#         # Derivative of the sigmoid function, used in backpropagation\n",
    "#         return x * (1 - x)\n",
    "\n",
    "#     def forward_propagation(self, x):\n",
    "#         # Forward pass to calculate the network's prediction\n",
    "#         self.hidden_input = np.dot(x, self.hidden_weights) + self.hidden_bais\n",
    "#         self.hidden_output = self.sigmoid(self.hidden_input)\n",
    "\n",
    "#         self.output_input = np.dot(self.hidden_output, self.output_weights) + self.output_bais\n",
    "#         self.output = self.sigmoid(self.output_input)\n",
    "#         return self.output\n",
    "    \n",
    "#     def backward_propagation(self, X, Y, output):\n",
    "#         # Backward pass to update weights and biases\n",
    "#         error = Y - output\n",
    "#         delta_op_layer = error * self.sigmoid_derivative(output)\n",
    "\n",
    "#         hidden_error = delta_op_layer.dot(self.output_weights.T)\n",
    "#         delta_hidden = hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "#         # Adjust weights and biases using the calculated gradients\n",
    "#         self.output_weights += self.hidden_output.T.dot(delta_op_layer)\n",
    "#         self.output_bais += np.sum(delta_op_layer, axis=0, keepdims=True)\n",
    "#         self.hidden_weights += X.T.dot(delta_hidden)\n",
    "#         self.hidden_bais += np.sum(delta_hidden, axis=0, keepdims=True)\n",
    "    \n",
    "#     def train(self, X, Y, epochs=100):\n",
    "#         # Training loop\n",
    "#         for epoch in range(epochs):\n",
    "#             output = self.forward_propagation(X)\n",
    "#             self.backward_propagation(X, Y, output)\n",
    "#             if epoch % 100 == 0:\n",
    "#                 loss = np.mean(np.square(Y - output))\n",
    "#                 print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "\n",
    "# # Example usage of the neural network\n",
    "# X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Input data\n",
    "# y = np.array([[0], [1], [1], [0]])  # Target output data\n",
    "# ip_size = 2  # Input layer size\n",
    "# hidden_size = 4  # Hidden layer size\n",
    "# op_size = 1  # Output layer size\n",
    "\n",
    "# nn = NN(ip_size, hidden_size, op_size)  # Create an instance of the neural network\n",
    "# nn.train(X, y, epochs=1000)  # Train the network\n",
    "\n",
    "# print(\"Prediction after Training:\")\n",
    "# print(nn.forward_propagation(X))  # Display the network's predictions after training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
